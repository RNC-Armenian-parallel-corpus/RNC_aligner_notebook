{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgXqs_xmuPgR"
      },
      "source": [
        "# Скрипт для выравнивания параллельных текстов на армянском и русском языках"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Описание"
      ],
      "metadata": {
        "id": "djUwZcwMa1QR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Эта тетрадь предназначена для выравнивания пар текстов на восточноармянском и русском языках с помощью библиотеки lingtrain-align (v1.0.2).\n",
        "\n",
        "Если описывать кратко, принцип работы следующий: в панель файлов слева пользователь загружает пару текстов, которые нужно выровнять; при необходимости пара текстов проходит проверку на параллельность, и если тексты оказываются не параллельными, \"корневая\" часть названия добавляется в исключения; если пара файлов параллельная, то предложения сопоставляются друг другу в excel-таблице; в итоге получается zip-архив с таблицами (=выровненными текстами в папке `output_dir` (по умолчанию назвается `result`)) и txt-файлом с исключениями. Сама таблица состоит из двух столбцов -- в первом столбце предложения на языке оригинала, во втором -- на языке перевода.\n",
        "\n",
        "Обработку можно проводить в несколько подходов: например, сегодня вы можете загрузить архив с файлами (назовем его `archive_raw.zip`), выровнять только часть, скачать архив с уже выровненными текстами + исключения (назовем его `archive_aligned.zip`), а на следующий день снова загрузить в блокнот эти два архива, распаковав `archive_aligned.zip` в папку `result`. В блокноте предусмотрена проверка текстов на их \"готовность\", поэтому уже обработанные в предыдущий день файлы заново не обработаются.\n",
        "\n",
        "Требования:\n",
        "- тексты должны быть в формате `.txt` и названы по маске `{title}_{am|ru}.txt`, например, `news_21312_am.txt` -- какая-то новостная статья под номером 21312 на армянском языке; ее парой на русском будет `news_21312_ru.txt`. `news_21312` здесь \"корневая\" часть названия, которая ОБЯЗАТЕЛЬНО должна совпадать у пары текстов; `ru` и `am` это указание языка -- русский и восточноармянский соответственно.\n",
        "- пары текстов можно положить на один уровень с `sample_data` или в отдельно созданную папку, название которой необходимо указать в переменной `INPUT_DIR`\n",
        "- если файлов много, их можно загрузить в `.zip` архиве. Далее в блокноте есть команды, которые позволят разархивировать эти файлы либо на уровне с `sample_data`, либо в папку `INPUT_DIR`.\n",
        "- проверка на параллельность осуществляется на первых 5 тыс. знаков текста, поэтому имеет смысл запускать ее только на коротких текстах, например, на новостных статьях. Большие книги лучше проверять вручную на количество глав, введений, послесловий, наличие содержания и т.д.\n",
        "\n",
        "\n",
        "\n",
        "- Статья про lingtrain-align и метки для указания метинформации https://habr.com/ru/articles/704958/\n",
        "- lingtrain-align на github https://github.com/averkij/lingtrain-aligner/tree/main\n",
        "- Этот блокнот основан на https://colab.research.google.com/drive/1lgmgCJuFAqjEI2zqn9RWPcQuO6rxC80f?usp=sharing#scrollTo=bZ0ZlbNqqjV6"
      ],
      "metadata": {
        "id": "4s4vamw6ZC5i"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VswIZz8-qAlG",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83f7539e-902e-4f83-e647-1186a293d651",
        "cellView": "form"
      },
      "source": [
        "#@title Устанавливаем зависимости\n",
        "\n",
        "!pip install -q -U lingtrain-aligner==1.0.2\n",
        "!pip install -q razdel dateparser sentence_transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.3/68.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31z_1uWuqBzA",
        "cellView": "form"
      },
      "source": [
        "#@title Импортируем библиотеки\n",
        "#@markdown Для выравнивания используется модель `sentence_transformer_multilingual`\n",
        "\n",
        "import os\n",
        "# import zipfile\n",
        "import shutil\n",
        "import datetime\n",
        "\n",
        "from lingtrain_aligner import preprocessor, splitter, aligner, resolver, reader, helper, vis_helper\n",
        "import pandas as pd\n",
        "import itertools\n",
        "\n",
        "model_name = 'sentence_transformer_multilingual' # или sentence_transformer_multilingual_labse"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Класс для обработки\n",
        "#@markdown - MAX_CONFLICT_COEFF менять только если в случае острой необходимости.\n",
        "#@markdown - CHRF_THRESHOLD -- пороговое значение chrF.\n",
        "\n",
        "# коэффициент для вычисления максимально допустимой длины конфликтов\n",
        "# максимальная длина вычисляется по формуле MAX_CONFLICT_COEFF*(i+1), где i -- номер шага {0...4}\n",
        "MAX_CONFLICT_COEFF = 5 # @param {\"type\":\"integer\"}\n",
        "\n",
        "# chrF, при значении ниже которого пара текстов считается не параллельной\n",
        "CHRF_THRESHOLD = 0.7 # @param {\"type\":\"number\"}\n",
        "\n",
        "class pair2Align:\n",
        "\n",
        "    def __init__(self, path_from: str, path_to: str,\n",
        "                 project_name: str, output_dir: str, lang_from: str, lang_to: str,\n",
        "                 model_name: str, check_chrf: bool=False) -> None:\n",
        "      \"\"\"\n",
        "      Взять пару текстов, при необходимости проверить на параллельность, выровнять в excel-таблицу.\n",
        "\n",
        "      Args:\n",
        "        path_from (str): Путь к тексту оригинала.\n",
        "        path_to (str): Путь к тексту перевода.\n",
        "        project_name (str): \"Корневое\" название пары текстов (см. \"Описание\" в самом начале блокнота).\n",
        "        output_dir (str): куда сохранить таблицу\n",
        "        lang_from (str): Язык оригинала (hy, ru).\n",
        "        lang_to (str): Язык перевода (hy, ru).\n",
        "        model (str): Название модели.\n",
        "        check_chrf (bool): Нужна ли проверка на параллельность (см. \"Описание\" в самом начале блокнота).\n",
        "      \"\"\"\n",
        "\n",
        "      self.text_from_name = path_from\n",
        "      self.text_to_name = path_to\n",
        "\n",
        "      assert project_name, 'Нужно передать название текста!'\n",
        "      self.project_name = project_name\n",
        "\n",
        "      self.output_dir = output_dir\n",
        "\n",
        "      self.db_path = project_name + '.db'\n",
        "\n",
        "      self.lang_from = lang_from\n",
        "      self.lang_to = lang_to\n",
        "\n",
        "      self.model_name = model_name\n",
        "\n",
        "      self.check_chrf = check_chrf\n",
        "\n",
        "      # конфигурации для формирования html-документа\n",
        "      self.lang_ordered = [\"from\", \"to\"]\n",
        "\n",
        "      # запускаем обработку\n",
        "      self.launch_pipe()\n",
        "\n",
        "    def launch_pipe(self) -> None:\n",
        "      \"\"\"\n",
        "      Запустить обработку текстов\n",
        "      \"\"\"\n",
        "\n",
        "      # читаем тексты в память\n",
        "      self.load_from() # заполняется переменная self.text_from\n",
        "      self.load_to() # заполняется переменная self.text_to\n",
        "\n",
        "      if self.check_chrf:\n",
        "        # проверяем на условную параллельность на первых 3 тыс. знаков\n",
        "        chrf = calc_chrf(''.join(self.text_from[:100])[:3000] if self.lang_to=='ru' \\\n",
        "                                else ''.join(self.text_to[:100])[:3000],\n",
        "                                ''.join(self.text_to[:100])[:3000] if self.lang_to=='ru' \\\n",
        "                                else ''.join(self.text_from[:100])[:3000])\n",
        "\n",
        "        if chrf < CHRF_THRESHOLD:\n",
        "          print(f'❌ НЕПАРАЛЛЕЛЬНЫЕ ТЕКСТЫ {self.project_name}! chrF =', chrf)\n",
        "          exceptions.append(self.project_name) # добавляем в глобальную переменную exceptions\n",
        "          return\n",
        "        else:\n",
        "          print(f'✅ {self.project_name}: chrF =', chrf)\n",
        "\n",
        "      self.split_by_sent() # разделить по предложениям\n",
        "      self.align() # выровнять, вернуть конфликты\n",
        "      self.resolve_conflicts() # разрешить конфликты\n",
        "      self.get_aligned() # сформировать таблицу\n",
        "\n",
        "      self.save_table(self.output_dir, self.project_name)\n",
        "\n",
        "    def load_from(self) -> None:\n",
        "      \"\"\"\n",
        "      Загрузить в память оригинальный текст\n",
        "      \"\"\"\n",
        "\n",
        "      with open(self.text_from_name, \"r\", encoding=\"utf8\") as input1:\n",
        "        self.text_from = input1.readlines()\n",
        "      print(f'Загружен оригинальный текст из {self.text_from_name}')\n",
        "\n",
        "    def load_to(self) -> None:\n",
        "      \"\"\"\n",
        "      Загрузить в память текст перевода\n",
        "      \"\"\"\n",
        "\n",
        "      with open(self.text_to_name, \"r\", encoding=\"utf8\") as input2:\n",
        "        self.text_to = input2.readlines()\n",
        "      print(f'Загружен текст перевода из {self.text_to_name}')\n",
        "\n",
        "    def split_by_sent(self) -> None:\n",
        "      \"\"\"\n",
        "      Разделить тексты по абзацам и предложениям\n",
        "      \"\"\"\n",
        "\n",
        "      text_from_prepared = preprocessor.mark_paragraphs(self.text_from)\n",
        "      text_to_prepared = preprocessor.mark_paragraphs(self.text_to)\n",
        "\n",
        "      self.splitted_from = splitter.split_by_sentences_wrapper(text_from_prepared, self.lang_from)\n",
        "      self.splitted_to = splitter.split_by_sentences_wrapper(text_to_prepared, self.lang_to)\n",
        "\n",
        "      print(f'Предложений в оригинальном тексте ({self.lang_from}):', len(self.splitted_from))\n",
        "      print(f'Предложений в тексте перевода ({self.lang_to})', len(self.splitted_to))\n",
        "\n",
        "    def align(self):\n",
        "      \"\"\"\n",
        "      Выровнять предложения, визуализировать соответствие предложений, вернуть конфликты.\n",
        "      \"\"\"\n",
        "\n",
        "      if os.path.isfile(self.db_path):\n",
        "        os.unlink(self.db_path)\n",
        "\n",
        "      aligner.fill_db(self.db_path, self.lang_from, self.lang_to, self.splitted_from, self.splitted_to)\n",
        "\n",
        "      aligner.align_db(self.db_path, \\\n",
        "                      self.model_name, \\\n",
        "                      batch_size=100, \\\n",
        "                      window=40, \\\n",
        "                      # batch_ids=batch_ids, \\\n",
        "                      save_pic=False,\n",
        "                      embed_batch_size=10, \\\n",
        "                      normalize_embeddings=True, \\\n",
        "                      show_progress_bar=True\n",
        "                      )\n",
        "      vis_helper.visualize_alignment_by_db(self.db_path, output_path='viz.png',\n",
        "                                           lang_name_from=self.lang_from,\n",
        "                                           lang_name_to=self.lang_to,\n",
        "                                           batch_size=400, size=(800,800),\n",
        "                                           plt_show=True)\n",
        "\n",
        "\n",
        "    def resolve_conflicts(self, steps: int=5) -> None:\n",
        "      \"\"\"\n",
        "      Разрешить конфликты.\n",
        "\n",
        "      Args:\n",
        "\n",
        "      steps (int): количество циклов разрешения конфликтов\n",
        "      \"\"\"\n",
        "      batch_id = -1 # выровнять все доступные батчи\n",
        "\n",
        "      for i in range(steps):\n",
        "          conflicts, rest = resolver.get_all_conflicts(self.db_path, min_chain_length=2+i,\n",
        "                                                       max_conflicts_len=MAX_CONFLICT_COEFF*(i+1),\n",
        "                                                       batch_id=batch_id,\n",
        "                                                       handle_start=True,\n",
        "                                                       handle_finish=True)\n",
        "          resolver.resolve_all_conflicts(self.db_path, conflicts, self.model_name, show_logs=False)\n",
        "          vis_helper.visualize_alignment_by_db(self.db_path, output_path='viz.png',\n",
        "                                               lang_name_from=self.lang_from,\n",
        "                                               lang_name_to=self.lang_to,\n",
        "                                               batch_size=400, size=(600,600),\n",
        "                                               plt_show=True)\n",
        "\n",
        "          if len(rest) == 0: break\n",
        "      print('Конфликты разрешены')\n",
        "\n",
        "    def save_book(self, output_filename: str, output_dir: str=None, custom_styles: list[str]=[]) -> None:\n",
        "      \"\"\"\n",
        "      Сохранить выровненные тексты как html-документ с цветовым обозначением параллельных предложений.\n",
        "\n",
        "      Args:\n",
        "\n",
        "      output_filename (str): название файла\n",
        "      output_dir (str): название папки\n",
        "      custom_styles (list): список со словарем css-свойств (словарь передается списком:\n",
        "      my_style = [\n",
        "          '{\"background\": \"#A2E4B8\", \"color\": \"black\", \"border-bottom\": \"0px solid red\"}',\n",
        "          '{\"background\": \"#FFC1CC\", \"color\": \"black\"}',\n",
        "          '{\"background\": \"#9BD3DD\", \"color\": \"black\"}',\n",
        "          '{\"background\": \"#FFFCC9\", \"color\": \"black\"}'\n",
        "          ]\n",
        "      save_book(custom_styles=my_style)\n",
        "      \"\"\"\n",
        "      output_path = os.path.join(output_dir, output_filename +\".html\")\n",
        "      if not os.path.exists(output_dir):\n",
        "        os.mkdir(output_dir)\n",
        "\n",
        "      paragraphs, delimeters, metas, sent_counter = reader.get_paragraphs(\n",
        "          self.db_path, direction=\"to\"\n",
        "      )\n",
        "\n",
        "      reader.create_book(\n",
        "          lang_ordered=self.lang_ordered,\n",
        "          paragraphs=paragraphs,\n",
        "          delimeters=delimeters,\n",
        "          metas=metas,\n",
        "          sent_counter=sent_counter,\n",
        "          output_path=output_path,\n",
        "          template=\"pastel_fill\",\n",
        "          styles=custom_styles,\n",
        "      )\n",
        "\n",
        "    def get_aligned(self) -> None:\n",
        "      \"\"\"\n",
        "      Сохранить выровненные предложения в pandas DataFrame.\n",
        "      \"\"\"\n",
        "\n",
        "      paragraphs_from, paragraphs_to, meta, _ = reader.get_paragraphs(self.db_path)\n",
        "\n",
        "      sents_from = list(itertools.chain.from_iterable(paragraphs_from['from']))\n",
        "      sents_to = list(itertools.chain.from_iterable(paragraphs_from['to']))\n",
        "\n",
        "      self.aligned_df = pd.DataFrame(data=[sents_from, sents_to],\n",
        "                                     index=[self.lang_from, self.lang_to]).T\n",
        "\n",
        "    def save_table(self, output_dir: str, out_filename: str) -> None:\n",
        "      \"\"\"\n",
        "      Сохранить выровненные предложения в эксель-таблицу.\n",
        "\n",
        "      Args:\n",
        "      output_dir (str): название файла без расширения\n",
        "      out_filename (str): название папки, куда нужно сохранить таблицу\n",
        "      \"\"\"\n",
        "      # сохраняем в excel а не в csv на случай, если нужно будет подправить что-то руками\n",
        "      self.aligned_df.to_excel(f'{output_dir}/{out_filename}.xlsx', index=False)\n",
        "\n",
        "\n",
        "def simple_align(path_from: str, path_to: str, project_name: str, output_dir: str) -> None:\n",
        "  \"\"\"\n",
        "  Простое выравнивание посредством слепления всего файла в одну строку.\n",
        "  Текст на армянском помещается в первый столбец, на русском -- во второй.\n",
        "\n",
        "  Args:\n",
        "\n",
        "  path_from (str): путь к тексту-оригиналу\n",
        "  path_to (str): путь к тексту-переводу\n",
        "  project_name (str): \"корневое\" название файлов (см. \"Описание\" в начале блокнота)\n",
        "  output_dir (str): в какую папку сохранить выровненный файл\n",
        "  \"\"\"\n",
        "\n",
        "  with open(path_from, 'r', encoding='utf8') as am_f:\n",
        "    am_text = ' '.join(am_f.readlines()).strip()\n",
        "\n",
        "  with open(path_to, 'r', encoding='utf8') as ru_f:\n",
        "    ru_text = ' '.join(ru_f.readlines()).strip()\n",
        "\n",
        "  df = pd.DataFrame(data=[am_text, ru_text], index=['hy', 'ru']).T\n",
        "  df = df.replace(r'\\s+', ' ', regex=True)\n",
        "\n",
        "  df.to_excel(os.path.join(output_dir, project_name+'.xlsx'), index=False)\n",
        "  print('ONELINER')\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "def backup(dir: str, exceptions_file: str, ts: str, if_download: False=False) -> None:\n",
        "  \"\"\"\n",
        "  Сохранить прогресс в архив. В него добавится файл с исключениями и содержимое папки с выровненными текстами.\n",
        "  В блокноте предусмотрено сохранение каждые 500 текстов\n",
        "\n",
        "  Args:\n",
        "\n",
        "  dir (str): папка, которую нужно заархивировать\n",
        "  exceptions_file (str): путь к файлу с исключениями\n",
        "  ts (str): время сохранения\n",
        "  if_download (bool): нужно ли загружать архив на компьютер?\n",
        "  \"\"\"\n",
        "  with open(exceptions_file, 'w') as file:\n",
        "      file.write('\\n'.join(exceptions) + '\\n')\n",
        "\n",
        "  zip_filename = OUTPUT_DIR + '_' + ts\n",
        "  shutil.make_archive(zip_filename, 'zip', dir)\n",
        "\n",
        "  if if_download:\n",
        "    files.download(zip_filename+'.zip')\n",
        "    files.download(exceptions_file)"
      ],
      "metadata": {
        "id": "r9Uem_MwksmL",
        "cellView": "form"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Проверка на параллельность (OPTIONAL)"
      ],
      "metadata": {
        "id": "vJXZcZUhjMfN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Перед выравниванием проверяем пары текстов на параллельность и исключаем непараллельные тексты\n",
        "\n",
        "Непосредственно параллельность проверить не получится, поэтому будем опираться нан метрику chrF.\n",
        "\n",
        "Процедура:\n",
        "1) переводим текст на армянском на русский\n",
        "2) считаем chrF\n",
        "3) если chrF меньше порога, то добавляем пару текстов в исключения  "
      ],
      "metadata": {
        "id": "RsI3a4a-YuFB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deep-translator"
      ],
      "metadata": {
        "id": "aRg8biOJfo5B",
        "outputId": "7eeb90ff-b6c4-4b3c-8e86-e1e03d928964",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deep-translator\n",
            "  Downloading deep_translator-1.11.4-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /usr/local/lib/python3.12/dist-packages (from deep-translator) (4.13.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from deep-translator) (2.32.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (2.8.3)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2026.1.4)\n",
            "Downloading deep_translator-1.11.4-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: deep-translator\n",
            "Successfully installed deep-translator-1.11.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from deep_translator import GoogleTranslator\n",
        "from nltk.translate.chrf_score import sentence_chrf\n",
        "\n",
        "def calc_chrf(armenian_true: str, russian_true: str) -> float:\n",
        "  \"\"\"\n",
        "  Перевести текст с армянского на русский и посчитать chrF.\n",
        "\n",
        "  Args:\n",
        "\n",
        "  armenian_true (str): текст на армянском\n",
        "  russian_true (str): текст на русском\n",
        "\n",
        "  Returns: значение chrF в диапазоне от 0 до 1\n",
        "  \"\"\"\n",
        "  translator = GoogleTranslator(source='armenian', target='russian')\n",
        "  russian_trans = translator.translate(armenian_true) # перевод армянского текста на русский\n",
        "\n",
        "  chrf_score = sentence_chrf(russian_true, russian_trans)\n",
        "\n",
        "  return chrf_score"
      ],
      "metadata": {
        "id": "mmloN8cBu2us"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Выравнивание"
      ],
      "metadata": {
        "id": "jk2vQud8XhKD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Если есть файлы, которые нужно исключить вручную, то перечисляем их в переменной exceptions.\n",
        "\n",
        "Указываем только основную часть названия -- то есть без расширения и кода языка.\n",
        "Например, есть файлы `news_12312_am.txt` и `news_12312_ru.txt`, которые мы хотим исключить, тогда в список добавляем значение `'news_12312'`"
      ],
      "metadata": {
        "id": "u7cMyqLSL_38"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title исключения\n",
        "exceptions = []\n",
        "exceptions_file = '_exceptions.txt' # @param {\"type\":\"string\"}\n",
        "\n",
        "if not os.path.exists(exceptions_file):\n",
        "  print(f'The specified file does not exist! Created new file {exceptions_file}')\n",
        "  with open(exceptions_file, 'w+') as file:\n",
        "    pass\n",
        "\n",
        "with open(exceptions_file, 'r+') as file:\n",
        "    # Read all lines and create a list\n",
        "    exceptions.extend(file.read().splitlines())\n",
        "print('Количество исключений:', len(exceptions))\n",
        "print('Исключения:', exceptions)\n"
      ],
      "metadata": {
        "id": "9Pk3uakFjcQK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "175f3ef9-2175-4f44-e291-d5fefec4d4fd",
        "cellView": "form"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество исключений: 1\n",
            "Исключения: ['000000003']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# OPTIONAL: вытаскиваем из архива уже выровненные тексты в папку\n",
        "# (если например нужно обработать много пар текстов в два дня, можно сохранить прогресс в архив и продолжить обрабатывать остаток в другой день)\n",
        "\n",
        "# ! unzip result_20260109_195034.zip -d result"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Wc3A3MJhYr5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# вытаскиваем из архива пары текстов в формате .txt на один уровень с sample_data\n",
        "! unzip news.zip\n",
        "\n",
        "# вытаскиваем из архива пары текстов в формате .txt в папку input\n",
        "# ! unzip {input_zip}.zip -d input"
      ],
      "metadata": {
        "collapsed": true,
        "id": "acBgkqN6XKqA",
        "outputId": "ae356ffb-5338-4ed4-b45d-04a085d7f78b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  news.zip\n",
            "  inflating: 000000004_am.txt        \n",
            "  inflating: 000000004_ru.txt        \n",
            "  inflating: 000000003_am.txt        \n",
            "  inflating: 000000003_ru.txt        \n",
            "  inflating: 000000001_am.txt        \n",
            "  inflating: 000000001_ru.txt        \n",
            "  inflating: 000000005_am.txt        \n",
            "  inflating: 000000005_ru.txt        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# OPTIONAL: ожидается, что файлы с текстами названы в формате {title}_{am|ru}.txt . Если язык текста указан в самом начале, то файлы следует переименовать\n",
        "\n",
        "\n",
        "# fnames = list(filter(\n",
        "#     lambda f: f.endswith('.txt') and re.sub('(am_|ru_)','', f).replace('.txt', '') not in done+exceptions,\n",
        "#     os.listdir(input_dir if input_dir else None)\n",
        "# ))\n",
        "# for f in fnames:\n",
        "#   lang_ = f.split('_')[0]\n",
        "#   new_name = f[3:].split('.')[0] + f'_{lang_}.txt'\n",
        "#   os.rename(os.path.join(input_dir, f), os.path.join(input_dir, new_name))"
      ],
      "metadata": {
        "id": "kynTqG7BAc_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Запускаем обработку текстов\n",
        "\n",
        "#@markdown - `INPUT_DIR` -- папка, где лежат пары файлов. Оставляем пустым, если файлы не лежат в какой-либо папке\n",
        "#@markdown - `OUTPUT_DIR` -- папка, в которую нужно положить выровненные тексты\n",
        "#@markdown - `LANG_FROM` -- язык оригинала\n",
        "#@markdown - `LANG_TO` -- язык перевода\n",
        "#@markdown - `CHECK_CHRF_FLAG` -- нужно ли проверять на параллельность? Включаем только для коротких текстов типа новостных статей\n",
        "\n",
        "from types import NoneType\n",
        "import os\n",
        "import re\n",
        "\n",
        "INPUT_DIR = '' # @param {\"type\":\"string\"}\n",
        "OUTPUT_DIR = 'result' # @param {\"type\":\"string\"}\n",
        "if not os.path.exists(OUTPUT_DIR):\n",
        "  os.mkdir(OUTPUT_DIR)\n",
        "\n",
        "done = os.listdir(OUTPUT_DIR)\n",
        "done = list(map(lambda f: f.replace('.xlsx', ''), done))\n",
        "\n",
        "fnames = list(filter(\n",
        "    lambda f: f.endswith('.txt') and re.sub('(_am|_ru)','', f).replace('.txt', '') not in done+exceptions,\n",
        "    os.listdir(INPUT_DIR if INPUT_DIR else None)\n",
        "))\n",
        "if exceptions_file in fnames:\n",
        "  fnames.remove(exceptions_file)\n",
        "fnames = set(map(lambda f: re.sub('(_am|_ru)', '', f).replace('.txt', ''), fnames))\n",
        "\n",
        "# язык оригинала\n",
        "LANG_FROM = \"hy\" # @param [\"hy\",\"ru\"]\n",
        "# язык перевода\n",
        "LANG_TO = \"ru\" # @param [\"hy\",\"ru\"]\n",
        "\n",
        "CHECK_CHRF_FLAG = True # @param {\"type\":\"boolean\"}\n",
        "\n",
        "cntr = 1\n",
        "\n",
        "for project_name in sorted(fnames):\n",
        "\n",
        "  if cntr % 500 == 0:\n",
        "    backup(dir=OUTPUT_DIR, exceptions_file=exceptions_file,\n",
        "           ts=datetime.datetime.now().strftime('%Y%m%d_%H%M%S'), if_download=False)\n",
        "\n",
        "  print(datetime.datetime.now().strftime('%H:%M:%S'))\n",
        "  print(project_name)\n",
        "\n",
        "  cur_timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "  db_path = f\"{cur_timestamp}.db\"\n",
        "\n",
        "  # название файла на русском (до .txt)\n",
        "  ru_input = f\"{project_name}_ru\"\n",
        "  # название файла на армянском (до .txt)\n",
        "  am_input = f\"{project_name}_am\"\n",
        "  # print(ru_input, am_input)\n",
        "\n",
        "  ru_input = ru_input+'.txt'\n",
        "  am_input = am_input+'.txt'\n",
        "\n",
        "  # print(ru_input, am_input)\n",
        "\n",
        "  try:\n",
        "    pair2Align(\n",
        "        path_from=os.path.join(INPUT_DIR, am_input) if LANG_FROM == \"hy\" \\\n",
        "                  else os.path.join(INPUT_DIR, ru_input),\n",
        "        path_to=os.path.join(INPUT_DIR, am_input) if LANG_TO == \"hy\" \\\n",
        "                  else os.path.join(INPUT_DIR, ru_input),\n",
        "        project_name=project_name,\n",
        "        output_dir=OUTPUT_DIR,\n",
        "        lang_from=LANG_FROM,\n",
        "        lang_to=LANG_TO,\n",
        "        model_name=model_name,\n",
        "        check_chrf=CHECK_CHRF_FLAG\n",
        "    )\n",
        "  except TypeError:\n",
        "    # ошибка выбрасывается, когда файл состоит из одной строки текста\n",
        "    simple_align(\n",
        "        path_from=os.path.join(INPUT_DIR, am_input) if LANG_FROM == \"hy\" \\\n",
        "                  else os.path.join(INPUT_DIR, ru_input),\n",
        "        path_to=os.path.join(INPUT_DIR, am_input) if LANG_TO == \"hy\" \\\n",
        "                  else os.path.join(INPUT_DIR, ru_input),\n",
        "        project_name=project_name,\n",
        "        output_dir=OUTPUT_DIR,\n",
        "    )\n",
        "\n",
        "  cntr += 1\n",
        "\n",
        "  print(cntr, 'done')\n",
        "  print('-'*50)\n",
        "\n",
        "backup(dir=OUTPUT_DIR, exceptions_file=exceptions_file,\n",
        "       ts=datetime.datetime.now().strftime('%Y%m%d_%H%M%S'), if_download=True)\n"
      ],
      "metadata": {
        "id": "r5bPe5zaXp6B",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1bf55f1547ca4e77aa0e212543e967aa",
            "cbcbe40b64a2418688ce03c311158060",
            "509c29b5435f48a895f28975d4d9bb27",
            "389219d83a724988a0fac24f9775ef09",
            "6fce340723784a27805f1f4dd6b5e6bc",
            "49b8f687700e470fb7e4aec8d88fde72",
            "640773e307f64367a3084711c2c0a3d9",
            "4cd21d36cf96415c9977ed730304c4f8",
            "284d6e14bac44ff58bc1ae3f242c01cb",
            "7ce63e9c229e44069ad20c827e692bf9",
            "9813a0067a4b43288932317f8cc8cd18",
            "eed3893ec8a640bdac5985d16a9dfe95",
            "c0e6e301314a4c4b99ba2caaddd475a9",
            "943204fec8354657aea0f155f3cc0c28",
            "e69d4ecbfeca4b37b37b33ddb023ac3f",
            "0128ca2ef53c473792133aa49fda1ae1",
            "56d54ca619c049a1b119ac941f9b389a",
            "2d94fc104b57469a80c5be4d001cd58e",
            "9d57ef36721d49a2a62d5616fc181b6d",
            "ed9806c878794768ac785321fa719fd8",
            "bcc41429f9ba418eb2c1bda7d7c78cf8",
            "78f480e8572742c4a780ca61fe8ea217"
          ]
        },
        "outputId": "bc43ccd9-c43c-42d2-8d68-1f641cdcaa0d",
        "collapsed": true,
        "cellView": "form"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17:18:08\n",
            "000000001\n",
            "Загружен оригинальный текст из 000000001_am.txt\n",
            "Загружен текст перевода из 000000001_ru.txt\n",
            "✅ 000000001: chrF = 0.7228680357059352\n",
            "Предложений в оригинальном тексте (hy): 5\n",
            "Предложений в тексте перевода (ru) 8\n",
            "Aligning without segments.\n",
            "tasks amount: 1\n",
            "batch: 0 (0)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1bf55f1547ca4e77aa0e212543e967aa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eed3893ec8a640bdac5985d16a9dfe95"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:can not fetch index db\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conflicts to solve: 0\n",
            "total conflicts: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Конфликты разрешены\n",
            "2 done\n",
            "--------------------------------------------------\n",
            "17:18:10\n",
            "000000004\n",
            "Загружен оригинальный текст из 000000004_am.txt\n",
            "Загружен текст перевода из 000000004_ru.txt\n",
            "❌ НЕПАРАЛЛЕЛЬНЫЕ ТЕКСТЫ 000000004! chrF = 0.61957496158942\n",
            "3 done\n",
            "--------------------------------------------------\n",
            "17:18:10\n",
            "000000005\n",
            "Загружен оригинальный текст из 000000005_am.txt\n",
            "Загружен текст перевода из 000000005_ru.txt\n",
            "❌ НЕПАРАЛЛЕЛЬНЫЕ ТЕКСТЫ 000000005! chrF = 0.6713110272735999\n",
            "4 done\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8cfbe702-41f9-4a67-a7b2-c3413a233a68\", \"result_20260215_171810.zip\", 5703)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8b95c10c-889d-4206-b0ab-c4402a5fbb67\", \"_exceptions.txt\", 30)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Исключений:', len(exceptions))\n",
        "# print(*sorted(exceptions), sep='\\n')"
      ],
      "metadata": {
        "id": "yrh0jc0V257Q",
        "outputId": "b5767fa7-086d-4479-9f84-184bad8d05c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Исключений: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# удаляем все\n",
        "\n",
        "# !rm *.db *.txt *.zip\n",
        "# !rm -r result"
      ],
      "metadata": {
        "id": "4Az-JXTgQ_S0"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}