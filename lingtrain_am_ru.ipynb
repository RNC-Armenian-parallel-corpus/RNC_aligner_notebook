{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgXqs_xmuPgR"
      },
      "source": [
        "# Демо-скрипт для выравнивания параллельных текстов на армянском и русском языках\n",
        "\n",
        "lingtrain-aligner==1.0.2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Сетап\n",
        "\n",
        "В качестве инпута подаются два txt-файла на армянском и русском. В скрипте предполагается, что эти файлы лежат на уровне скрипта. Если они лежат в другом месте, нужно прописать путь до файла в переменные `am_input` и `ru_input`. Название для файла, получаемого на выходе (html-документ с раскрашенными предложениями и выровненный csv) нужно задать в переменной `project_name`.\n",
        "\n",
        "В идеале хорошо бы разметить файлы на предмет метаинформации: `Лю Ци Синь%%%%%author.`, `Задача трёх тел%%%%%title.` и т.д., иначе заголовок сливается с основным текстом, т.к. между ними нет разделяющего знака препинания. Теги для такой разметки можно посмотреть в \"полезных ссылках ниже\".\n",
        "\n",
        "Результаты обработки сохраняются в папку `result` по умолчанию, но можно поменять название папки установив его в переменной `output_dir`.\n",
        "\n",
        "## Полезные ссылки\n",
        "- Статья про инструмент и метки для указания метинформации https://habr.com/ru/articles/704958/\n",
        "- github проекта https://github.com/averkij/lingtrain-aligner/tree/main\n",
        "- основывалась на скрипте https://colab.research.google.com/drive/1lgmgCJuFAqjEI2zqn9RWPcQuO6rxC80f?usp=sharing#scrollTo=bZ0ZlbNqqjV6"
      ],
      "metadata": {
        "id": "djUwZcwMa1QR"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VswIZz8-qAlG",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "162ee103-4f3b-4147-fb4b-54419a7b8749"
      },
      "source": [
        "#@title Установим зависимости\n",
        "\n",
        "!pip install -q -U lingtrain-aligner==1.0.2\n",
        "!pip install -q razdel dateparser sentence_transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.3/68.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.5/315.5 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31z_1uWuqBzA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b59e38f-bf44-48eb-c061-fe44ad91b36d"
      },
      "source": [
        "#@title Импортируем библиотеки\n",
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "import datetime\n",
        "\n",
        "from lingtrain_aligner import preprocessor, splitter, aligner, resolver, reader, helper, vis_helper\n",
        "import pandas as pd\n",
        "import itertools"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3LTah8juCUo"
      },
      "source": [
        "# зададим общие переменные\n",
        "output_dir = 'result'\n",
        "if not os.path.exists(output_dir):\n",
        "  os.mkdir(output_dir)\n",
        "\n",
        "models = [\"sentence_transformer_multilingual\", \"sentence_transformer_multilingual_labse\"]\n",
        "model_name = models[0]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Класс для обработки (нужно запустить)\n",
        "\n",
        "# количество итераций для разрешения конфликтов\n",
        "MAX_ITERATIONS = 3 # @param {\"type\":\"integer\"}\n",
        "\n",
        "class pair2Align:\n",
        "    def __init__(self, text_from_name, text_to_name, project_name, lang_from, lang_to, model):\n",
        "\n",
        "      self.success = False\n",
        "\n",
        "      self.text_from_name = text_from_name\n",
        "      self.text_to_name = text_to_name\n",
        "      assert project_name, 'Нужно передать название текста!'\n",
        "      self.project_name = project_name\n",
        "      self.db_path = project_name + '.db'\n",
        "\n",
        "      self.lang_from = lang_from\n",
        "      self.lang_to = lang_to\n",
        "\n",
        "      # конфигурации для формирования html-документа\n",
        "      self.lang_ordered = [\"from\", \"to\"]\n",
        "\n",
        "      # запускаем пайп\n",
        "      self.load_from()\n",
        "      self.load_to()\n",
        "\n",
        "      # проверяем на условную параллельность\n",
        "      chrf = nonparallel_bool(''.join(self.text_from[:100])[:3000] if lang_to=='ru' else ''.join(self.text_to[:100])[:3000], ''.join(self.text_to[:100])[:3000] if lang_to=='ru' else ''.join(self.text_from[:100])[:3000])\n",
        "      if chrf < 0.7:\n",
        "        print(f'НЕПАРАЛЛЕЛЬНЫЕ ТЕКСТЫ {self.project_name}! chrF =', chrf)\n",
        "        return\n",
        "\n",
        "      self.split_by_sent()\n",
        "      self.conflicts = self.align()\n",
        "      self.resolve_conflicts()\n",
        "      self.get_aligned()\n",
        "\n",
        "      self.success = True\n",
        "\n",
        "    def load_from(self):\n",
        "    # Оригинальный текст\n",
        "      with open(self.text_from_name, \"r\", encoding=\"utf8\") as input1:\n",
        "        self.text_from = input1.readlines()\n",
        "      print('Загружен оригинальный текст')\n",
        "\n",
        "    def load_to(self):\n",
        "    # Текст перевода\n",
        "      with open(self.text_to_name, \"r\", encoding=\"utf8\") as input2:\n",
        "        self.text_to = input2.readlines()\n",
        "      print('Загружен текст перевода')\n",
        "\n",
        "    def split_by_sent(self):\n",
        "      # Добавим метки абзацев, они пригодятся позже\n",
        "      text_from_prepared = preprocessor.mark_paragraphs(self.text_from)\n",
        "      text_to_prepared = preprocessor.mark_paragraphs(self.text_to)\n",
        "\n",
        "      self.splitted_from = splitter.split_by_sentences_wrapper(text_from_prepared, lang_from)\n",
        "      self.splitted_to = splitter.split_by_sentences_wrapper(text_to_prepared, lang_to)\n",
        "\n",
        "      print('Предложений в оригинальном тексте:', len(self.splitted_from))\n",
        "      print('Предложений в тексте перевода:', len(self.splitted_to))\n",
        "\n",
        "    def align(self):\n",
        "      \"\"\"\n",
        "      for c in conflicts_to_solve:\n",
        "        resolver.show_conflict(db_path, c)\n",
        "      \"\"\"\n",
        "\n",
        "      if os.path.isfile(self.db_path):\n",
        "        os.unlink(self.db_path)\n",
        "\n",
        "      aligner.fill_db(self.db_path, lang_from, lang_to, self.splitted_from, self.splitted_to)\n",
        "\n",
        "      batch_ids = [0,1]\n",
        "\n",
        "      aligner.align_db(self.db_path, \\\n",
        "                      model_name, \\\n",
        "                      batch_size=100, \\\n",
        "                      window=40, \\\n",
        "                      batch_ids=batch_ids, \\\n",
        "                      save_pic=False,\n",
        "                      embed_batch_size=10, \\\n",
        "                      normalize_embeddings=True, \\\n",
        "                      show_progress_bar=True\n",
        "                      )\n",
        "      # vis_helper.visualize_alignment_by_db(self.db_path, output_path='viz.png', lang_name_from=self.lang_from, lang_name_to=self.lang_to, batch_size=400, size=(800,800), plt_show=True)\n",
        "\n",
        "      return resolver.get_all_conflicts(self.db_path, min_chain_length=2, max_conflicts_len=MAX_ITERATIONS, batch_id=-1) # conflicts_to_solve, rest -> resolver.get_statistics(conflicts_to_solve), resolver.get_statistics(rest)\n",
        "\n",
        "\n",
        "    def resolve_conflicts(self, steps=5):\n",
        "      batch_id = -1 #выровнять все доступные батчи\n",
        "\n",
        "      for i in range(steps):\n",
        "          conflicts, rest = resolver.get_all_conflicts(self.db_path, min_chain_length=2+i, max_conflicts_len=MAX_ITERATIONS*(i+1), batch_id=batch_id, handle_start=True, handle_finish=True)\n",
        "          resolver.resolve_all_conflicts(self.db_path, conflicts, model_name, show_logs=False)\n",
        "          # vis_helper.visualize_alignment_by_db(self.db_path, output_path='viz.png', lang_name_from=self.lang_from, lang_name_to=self.lang_to, batch_size=400, size=(600,600), plt_show=True)\n",
        "\n",
        "          if len(rest) == 0: break\n",
        "      print('Конфликты разрешены')\n",
        "\n",
        "    def save_book(self, output_filename, output_dir=None, custom_styles=[]):\n",
        "      \"\"\"\n",
        "      # можно передать свои правила для оформления книжки\n",
        "      my_style = [\n",
        "          '{\"background\": \"#A2E4B8\", \"color\": \"black\", \"border-bottom\": \"0px solid red\"}',\n",
        "          '{\"background\": \"#FFC1CC\", \"color\": \"black\"}',\n",
        "          '{\"background\": \"#9BD3DD\", \"color\": \"black\"}',\n",
        "          '{\"background\": \"#FFFCC9\", \"color\": \"black\"}'\n",
        "          ]\n",
        "      save_aligned(custom_styles=my_style)\n",
        "      \"\"\"\n",
        "      output_path = os.path.join(output_dir, output_filename +\".html\")\n",
        "      if not os.path.exists(output_dir):\n",
        "        os.mkdir(output_dir)\n",
        "\n",
        "      paragraphs, delimeters, metas, sent_counter = reader.get_paragraphs(\n",
        "          self.db_path, direction=\"to\"\n",
        "      )\n",
        "\n",
        "      reader.create_book(\n",
        "          lang_ordered=self.lang_ordered,\n",
        "          paragraphs=paragraphs,\n",
        "          delimeters=delimeters,\n",
        "          metas=metas,\n",
        "          sent_counter=sent_counter,\n",
        "          output_path=output_path,\n",
        "          template=\"pastel_fill\",\n",
        "          styles=custom_styles,\n",
        "      )\n",
        "\n",
        "    def get_aligned(self):\n",
        "\n",
        "      paragraphs_from, paragraphs_to, meta, _ = reader.get_paragraphs(self.db_path)\n",
        "\n",
        "      sents_from = list(itertools.chain.from_iterable(paragraphs_from['from']))\n",
        "      sents_to = list(itertools.chain.from_iterable(paragraphs_from['to']))\n",
        "\n",
        "      self.aligned_df = pd.DataFrame(data=[sents_from, sents_to], index=[self.lang_from, self.lang_to]).T\n",
        "\n",
        "    @staticmethod\n",
        "    def save_table(df, output_dir, out_filename):\n",
        "      \"\"\"\n",
        "      pair2Align.save_table(proj.aligned_df, output_dir, out_filename=project_name)\n",
        "      \"\"\"\n",
        "      # сохраняем в excel а не в csv на случай, если нужно будет подправить что-то руками\n",
        "      df.to_excel(f'{output_dir}/{out_filename}.xlsx', index=False)\n"
      ],
      "metadata": {
        "id": "r9Uem_MwksmL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lingtrain_align(am_input, ru_input, project_name, lang_from, lang_to, model_name):\n",
        "  \"\"\"\n",
        "  Выравнивание с помощью lingtrain-aligner\n",
        "  \"\"\"\n",
        "\n",
        "  proj = pair2Align(text_from_name=am_input, text_to_name=ru_input, project_name=project_name, lang_from=lang_from, lang_to=lang_to, model=model_name)\n",
        "  # print(proj.success)\n",
        "\n",
        "  # сохраняем таблицу с выровненными предложениями в папку\n",
        "  if proj.success:\n",
        "    pair2Align.save_table(proj.aligned_df, output_dir, out_filename=project_name)\n",
        "  else:\n",
        "    exceptions.append(proj.project_name)\n",
        "\n",
        "def simple_align(am_input, ru_input, project_name):\n",
        "  \"\"\"\n",
        "  Простое выравнивание посредством слепления всего файла в одну строку.\n",
        "  Текст на армянском помещается в первый столбец, на русском -- во второй.\n",
        "  \"\"\"\n",
        "\n",
        "  with open(am_input, 'r', encoding='utf8') as am_f:\n",
        "    am_text = ' '.join(am_f.readlines()).strip()\n",
        "\n",
        "  with open(ru_input, 'r', encoding='utf8') as ru_f:\n",
        "    ru_text = ' '.join(ru_f.readlines()).strip()\n",
        "\n",
        "  df = pd.DataFrame(data=[am_text, ru_text], index=['hy', 'ru']).T\n",
        "  df = df.replace('\\s+', ' ', regex=True)\n",
        "\n",
        "  df.to_excel(os.path.join(output_dir, project_name+'.xlsx'), index=False)\n",
        "  print('ONELINER')\n"
      ],
      "metadata": {
        "id": "2tK_5fGt1gaz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6e381f8-fdb0-436a-a525-5377505c3089"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:28: SyntaxWarning: invalid escape sequence '\\s'\n",
            "<>:28: SyntaxWarning: invalid escape sequence '\\s'\n",
            "/tmp/ipython-input-4145714848.py:28: SyntaxWarning: invalid escape sequence '\\s'\n",
            "  df = df.replace('\\s+', ' ', regex=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Перед выравниванием проверяем пары текстов на параллельность и исключаем непараллельные тексты\n",
        "\n",
        "Непосредственно параллельность проверить не получится, поэтому будем опираться нан метрику chrF.\n",
        "\n",
        "Процедура:\n",
        "1) переводим текст на армянском на русский\n",
        "2) считаем chrF\n",
        "3) если chrF меньше 80, то добавляем пару текстов в исключения  "
      ],
      "metadata": {
        "id": "vJXZcZUhjMfN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deep-translator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRg8biOJfo5B",
        "outputId": "4c8ed765-6433-4234-8f0f-658cde17678a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deep-translator\n",
            "  Downloading deep_translator-1.11.4-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /usr/local/lib/python3.12/dist-packages (from deep-translator) (4.13.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from deep-translator) (2.32.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2025.11.12)\n",
            "Downloading deep_translator-1.11.4-py3-none-any.whl (42 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: deep-translator\n",
            "Successfully installed deep-translator-1.11.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from deep_translator import GoogleTranslator\n",
        "from nltk.translate.chrf_score import sentence_chrf\n",
        "\n",
        "def nonparallel_bool(armenian_true, russian_true):\n",
        "  translator = GoogleTranslator(source='armenian', target='russian')\n",
        "  russian_trans = translator.translate(armenian_true)\n",
        "\n",
        "  chrf_score = sentence_chrf(russian_true, russian_trans)\n",
        "\n",
        "  return chrf_score"
      ],
      "metadata": {
        "id": "mmloN8cBu2us"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Запускаем обработку пар текстов в цикле"
      ],
      "metadata": {
        "id": "jk2vQud8XhKD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# если есть файлы, которые нужно исключить вручную, то перечисляем их в переменной exceptions.\n",
        "# Указываем только основную часть названия -- то есть без расширения и кода языка.\n",
        "# Например, есть файлы 1128107_am.txt и 1128107_ru.txt, которые мы хотим исключить, тогда в список добавляем значение 1128107\n",
        "exceptions = ['1128107']\n",
        "exceptions_file = 'armenpress_exceptions.txt'  # @param {\"type\":\"string\"}\n",
        "\n",
        "with open(exceptions_file, 'r') as file:\n",
        "    # Read all lines and create a list\n",
        "    exceptions.extend(file.read().splitlines())\n",
        "len('Количество исключений:', exceptions)"
      ],
      "metadata": {
        "id": "9Pk3uakFjcQK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OPTIONAL: вытаскиваем из архива уже выровненные тексты в папку\n",
        "# (если например нужно обработать 200 пар в два дня, можно сохранить прогресс в архив и продолжить обрабатывать остаток в другой день)\n",
        "! unzip result_20260109_195034.zip -d result"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Wc3A3MJhYr5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# архив с парными текстами без .zip\n",
        "input_zip = 'armenpress' # @param {\"type\":\"string\"}"
      ],
      "metadata": {
        "id": "7RH_ecP59brF"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# вытаскиваем из архива пары текстов в формате .txt\n",
        "! unzip {input_zip}.zip"
      ],
      "metadata": {
        "collapsed": true,
        "id": "acBgkqN6XKqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "def backup(exceptions_file, ts):\n",
        "  with open(exceptions_file, 'w') as file:\n",
        "      # Join the list items with a newline character and write to the file\n",
        "      file.write('\\n'.join(exceptions) + '\\n')\n",
        "\n",
        "  zip_filename = output_dir + '_' + ts\n",
        "  shutil.make_archive(zip_filename, 'zip', output_dir)"
      ],
      "metadata": {
        "id": "mIDFBvfMGD0p"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from types import NoneType\n",
        "import os\n",
        "import re\n",
        "\n",
        "# None, если файлы лежат в корневой папке\n",
        "input_dir = 'armenpress' # @param {\"type\":\"string\"}\n",
        "output_dir = 'result' # @param {\"type\":\"string\"}\n",
        "done = os.listdir(output_dir)\n",
        "done = list(map(lambda f: f.replace('.xlsx', ''), done))\n",
        "\n",
        "fnames = list(filter(lambda f: f.endswith('.txt') and re.sub('(_*am|am_*|_*ru|ru*_)', '', f).replace('.txt', '') not in done+exceptions, os.listdir(input_dir)))\n",
        "fnames = set(map(lambda f: re.sub('(_*am|am_*|_*ru|ru*_)', '', f).replace('.txt', ''), fnames))\n",
        "\n",
        "# язык оригинала\n",
        "lang_from = \"hy\" # @param [\"hy\",\"ru\"]\n",
        "# язык перевода\n",
        "lang_to = \"ru\" # @param [\"hy\",\"ru\"]\n",
        "\n",
        "cntr = 0\n",
        "\n",
        "for project_name in fnames:\n",
        "\n",
        "  if cntr % 500 == 0:\n",
        "    backup(exceptions_file=exceptions_file, ts=datetime.datetime.now().strftime('%Y%m%d_%H%M%S'))\n",
        "\n",
        "  print(datetime.datetime.now().strftime('%H:%M:%S'))\n",
        "  print(project_name)\n",
        "\n",
        "  cur_timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "  db_path = f\"{cur_timestamp}.db\"\n",
        "\n",
        "  # название файла на русском (до .txt)\n",
        "  ru_input = f\"{project_name}_ru\"\n",
        "  # название файла на армянском (до .txt)\n",
        "  am_input = f\"{project_name}_am\"\n",
        "  # print(ru_input, am_input)\n",
        "\n",
        "  ru_input = ru_input+'.txt'\n",
        "  am_input = am_input+'.txt'\n",
        "\n",
        "  # print(ru_input, am_input)\n",
        "\n",
        "  try:\n",
        "    lingtrain_align(os.path.join(input_dir, am_input), os.path.join(input_dir, ru_input), project_name, lang_from, lang_to, model_name)\n",
        "  except TypeError:\n",
        "    # такая ошибка выбрасывается, когда файл состоит из одной строки текста\n",
        "    simple_align(am_input, ru_input, project_name)\n",
        "\n",
        "  cntr += 1\n",
        "\n",
        "  print(cntr, 'done')\n",
        "  print('-'*50)\n",
        "\n",
        "backup(exceptions_file=exceptions_file, ts=datetime.datetime.now().strftime('%Y%m%d_%H%M%S'))\n",
        "files.download(zip_filename+'.zip')\n",
        "files.download(exceptions_file)\n"
      ],
      "metadata": {
        "id": "r5bPe5zaXp6B",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "24ead0a1-c3b2-41f2-e990-cfc431dbdb59"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_af7244f0-ba74-43aa-8f19-1eed019e4007\", \"result_20260110_080854.zip\", 8233147)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_af55ebf6-c69a-4954-8dbc-bb6548144aca\", \"armenpress_exceptions.txt\", 5344)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(len(os.listdir(input_dir))-1)/2 , len(set(exceptions))+len(done)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Td1A00LaOGci",
        "outputId": "eeee220f-32f5-4a57-e79b-548f82e60bf2"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1831.0, 1838)"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm *.db"
      ],
      "metadata": {
        "id": "4Az-JXTgQ_S0"
      },
      "execution_count": 86,
      "outputs": []
    }
  ]
}