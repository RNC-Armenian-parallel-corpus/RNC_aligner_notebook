{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgXqs_xmuPgR"
      },
      "source": [
        "# Демо-скрипт для выравнивания параллельных текстов на армянском и русском языках\n",
        "\n",
        "lingtrain-aligner==1.0.2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Сетап\n",
        "\n",
        "В качестве инпута подаются два txt-файла на армянском и русском. В скрипте предполагается, что эти файлы лежат на уровне скрипта. Если они лежат в другом месте, нужно прописать путь до файла в переменные `am_input` и `ru_input`. Название для файла, получаемого на выходе (html-документ с раскрашенными предложениями и выровненный csv) нужно задать в переменной `project_name`.\n",
        "\n",
        "В идеале хорошо бы разметить файлы на предмет метаинформации: `Лю Ци Синь%%%%%author.`, `Задача трёх тел%%%%%title.` и т.д., иначе заголовок сливается с основным текстом, т.к. между ними нет разделяющего знака препинания. Теги для такой разметки можно посмотреть в \"полезных ссылках ниже\".\n",
        "\n",
        "Результаты обработки сохраняются в папку `result` по умолчанию, но можно поменять название папки установив его в переменной `output_dir`.\n",
        "\n",
        "## Полезные ссылки\n",
        "- Статья про инструмент и метки для указания метинформации https://habr.com/ru/articles/704958/\n",
        "- github проекта https://github.com/averkij/lingtrain-aligner/tree/main\n",
        "- основывалась на скрипте https://colab.research.google.com/drive/1lgmgCJuFAqjEI2zqn9RWPcQuO6rxC80f?usp=sharing#scrollTo=bZ0ZlbNqqjV6"
      ],
      "metadata": {
        "id": "djUwZcwMa1QR"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VswIZz8-qAlG",
        "outputId": "0ced5ed5-3f5b-48c3-fb76-ec9152cf6f48",
        "collapsed": true
      },
      "source": [
        "#@title Установим зависимости\n",
        "\n",
        "!pip install -q -U lingtrain-aligner==1.0.2\n",
        "!pip install -q razdel dateparser sentence_transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.3/68.3 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.5/315.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m847.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31z_1uWuqBzA"
      },
      "source": [
        "#@title Импортируем библиотеки\n",
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "import datetime\n",
        "\n",
        "from lingtrain_aligner import preprocessor, splitter, aligner, resolver, reader, helper, vis_helper\n",
        "import pandas as pd\n",
        "import itertools"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3LTah8juCUo"
      },
      "source": [
        "# зададим общие переменные\n",
        "output_dir = 'result'\n",
        "if not os.path.exists(output_dir):\n",
        "  os.mkdir(output_dir)\n",
        "\n",
        "models = [\"sentence_transformer_multilingual\", \"sentence_transformer_multilingual_labse\"]\n",
        "model_name = models[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Класс для обработки (нужно запустить)\n",
        "class pair2Align:\n",
        "    def __init__(self, text_from_name, text_to_name, project_name, lang_from, lang_to, model):\n",
        "\n",
        "      self.text_from_name = text_from_name\n",
        "      self.text_to_name = text_to_name\n",
        "      assert project_name, 'Нужно передать название текста!'\n",
        "      self.project_name = project_name\n",
        "      self.db_path = project_name + '.db'\n",
        "\n",
        "      self.lang_from = lang_from\n",
        "      self.lang_to = lang_to\n",
        "\n",
        "      # конфигурации для формирования html-документа\n",
        "      self.lang_ordered = [\"from\", \"to\"]\n",
        "\n",
        "      # запускаем пайп\n",
        "      self.load_from()\n",
        "      self.load_to()\n",
        "      self.split_by_sent()\n",
        "      self.conflicts = self.align()\n",
        "      self.resolve_conflicts()\n",
        "      self.get_aligned()\n",
        "\n",
        "    def load_from(self):\n",
        "    # Оригинальный текст\n",
        "      with open(self.text_from_name, \"r\", encoding=\"utf8\") as input1:\n",
        "        self.text_from = input1.readlines()\n",
        "      print('Загружен оригинальный текст')\n",
        "\n",
        "    def load_to(self):\n",
        "    # Текст перевода\n",
        "      with open(self.text_to_name, \"r\", encoding=\"utf8\") as input2:\n",
        "        self.text_to = input2.readlines()\n",
        "      print('Загружен текст перевода')\n",
        "\n",
        "    def split_by_sent(self):\n",
        "      # Добавим метки абзацев, они пригодятся позже\n",
        "      text_from_prepared = preprocessor.mark_paragraphs(self.text_from)\n",
        "      text_to_prepared = preprocessor.mark_paragraphs(self.text_to)\n",
        "\n",
        "      self.splitted_from = splitter.split_by_sentences_wrapper(text_from_prepared, lang_from)\n",
        "      self.splitted_to = splitter.split_by_sentences_wrapper(text_to_prepared, lang_to)\n",
        "\n",
        "      print('Предложений в оригинальном тексте:', len(self.splitted_from))\n",
        "      print('Предложений в тексте перевода:', len(self.splitted_to))\n",
        "\n",
        "    def align(self):\n",
        "      \"\"\"\n",
        "      for c in conflicts_to_solve:\n",
        "        resolver.show_conflict(db_path, c)\n",
        "      \"\"\"\n",
        "\n",
        "      if os.path.isfile(self.db_path):\n",
        "        os.unlink(self.db_path)\n",
        "\n",
        "      aligner.fill_db(self.db_path, lang_from, lang_to, self.splitted_from, self.splitted_to)\n",
        "\n",
        "      batch_ids = [0,1]\n",
        "\n",
        "      aligner.align_db(self.db_path, \\\n",
        "                      model_name, \\\n",
        "                      batch_size=100, \\\n",
        "                      window=40, \\\n",
        "                      batch_ids=batch_ids, \\\n",
        "                      save_pic=False,\n",
        "                      embed_batch_size=10, \\\n",
        "                      normalize_embeddings=True, \\\n",
        "                      show_progress_bar=True\n",
        "                      )\n",
        "      vis_helper.visualize_alignment_by_db(self.db_path, output_path='viz.png', lang_name_from=self.lang_from, lang_name_to=self.lang_to, batch_size=400, size=(800,800), plt_show=True)\n",
        "\n",
        "      return resolver.get_all_conflicts(self.db_path, min_chain_length=2, max_conflicts_len=6, batch_id=-1) # conflicts_to_solve, rest -> resolver.get_statistics(conflicts_to_solve), resolver.get_statistics(rest)\n",
        "\n",
        "\n",
        "    def resolve_conflicts(self, steps=5):\n",
        "      batch_id = -1 #выровнять все доступные батчи\n",
        "\n",
        "      for i in range(steps):\n",
        "          conflicts, rest = resolver.get_all_conflicts(self.db_path, min_chain_length=2+i, max_conflicts_len=5*(i+1), batch_id=batch_id, handle_start=True, handle_finish=True)\n",
        "          resolver.resolve_all_conflicts(self.db_path, conflicts, model_name, show_logs=False)\n",
        "          vis_helper.visualize_alignment_by_db(self.db_path, output_path='viz.png', lang_name_from=self.lang_from, lang_name_to=self.lang_to, batch_size=400, size=(600,600), plt_show=True)\n",
        "\n",
        "          if len(rest) == 0: break\n",
        "      print('Конфликты разрешены')\n",
        "\n",
        "    def save_book(self, output_filename, output_dir=None, custom_styles=[]):\n",
        "      \"\"\"\n",
        "      # можно передать свои правила для оформления книжки\n",
        "      my_style = [\n",
        "          '{\"background\": \"#A2E4B8\", \"color\": \"black\", \"border-bottom\": \"0px solid red\"}',\n",
        "          '{\"background\": \"#FFC1CC\", \"color\": \"black\"}',\n",
        "          '{\"background\": \"#9BD3DD\", \"color\": \"black\"}',\n",
        "          '{\"background\": \"#FFFCC9\", \"color\": \"black\"}'\n",
        "          ]\n",
        "      save_aligned(custom_styles=my_style)\n",
        "      \"\"\"\n",
        "      output_path = os.path.join(output_dir, output_filename +\".html\")\n",
        "      if not os.path.exists(output_dir):\n",
        "        os.mkdir(output_dir)\n",
        "\n",
        "      paragraphs, delimeters, metas, sent_counter = reader.get_paragraphs(\n",
        "          self.db_path, direction=\"to\"\n",
        "      )\n",
        "\n",
        "      reader.create_book(\n",
        "          lang_ordered=self.lang_ordered,\n",
        "          paragraphs=paragraphs,\n",
        "          delimeters=delimeters,\n",
        "          metas=metas,\n",
        "          sent_counter=sent_counter,\n",
        "          output_path=output_path,\n",
        "          template=\"pastel_fill\",\n",
        "          styles=custom_styles,\n",
        "      )\n",
        "\n",
        "    def get_aligned(self):\n",
        "\n",
        "      paragraphs_from, paragraphs_to, meta, _ = reader.get_paragraphs(self.db_path)\n",
        "\n",
        "      sents_from = list(itertools.chain.from_iterable(paragraphs_from['from']))\n",
        "      sents_to = list(itertools.chain.from_iterable(paragraphs_from['to']))\n",
        "\n",
        "      self.aligned_df = pd.DataFrame(data=[sents_from, sents_to], index=[self.lang_from, self.lang_to]).T\n",
        "\n",
        "    @staticmethod\n",
        "    def save_table(df, output_dir, out_filename):\n",
        "      \"\"\"\n",
        "      pair2Align.save_table(proj.aligned_df, output_dir, out_filename=project_name)\n",
        "      \"\"\"\n",
        "      # сохраняем в excel а не в csv на случай, если нужно будет подправить что-то руками\n",
        "      df.to_excel(f'{output_dir}/{out_filename}.xlsx', index=False)\n"
      ],
      "metadata": {
        "id": "r9Uem_MwksmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Эту часть нужно перезапускать для каждой пары текстов"
      ],
      "metadata": {
        "id": "2YXrs6D-2LFE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Если текстов много (например, новостных), нужно добавить в скрипт цикл, который бы определял пары одного и того же текста (должны быть названы по маске) и автоматически запускал функцию. Но в таком случае уже не получится отслеживать качество выравнивания -- получается такой tradeoff."
      ],
      "metadata": {
        "id": "lu1f3wsaGNCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Переменные, уникальные для каждой пары текстов\n",
        "\n",
        "# название книги\n",
        "project_name = \"rooster\" #@param {\"type\":\"string\"}\n",
        "\n",
        "cur_timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "db_path = f\"{cur_timestamp}.db\"\n",
        "\n",
        "# название файла на русском (до .txt)\n",
        "ru_input = f\"tumanyan/ru_{project_name}\" #@param {\"type\":\"string\"}\n",
        "# название файла на армянском (до .txt)\n",
        "am_input = f\"tumanyan/am_{project_name}\" #@param {\"type\":\"string\"}\n",
        "\n",
        "ru_input = ru_input+'.txt'\n",
        "am_input = am_input+'.txt'\n",
        "\n",
        "# язык оригинала\n",
        "lang_from = \"hy\" # @param [\"hy\",\"ru\"]\n",
        "# язык перевода\n",
        "lang_to = \"ru\" # @param [\"hy\",\"ru\"]"
      ],
      "metadata": {
        "id": "tIDewuoXdoAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "proj = pair2Align(text_from_name=am_input, text_to_name=ru_input, project_name=project_name, lang_from=lang_from, lang_to=lang_to, model=model_name)"
      ],
      "metadata": {
        "id": "4Am59nSTyLM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "proj.aligned_df"
      ],
      "metadata": {
        "id": "X9NNqxCazk2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# сохраняем таблицу с выровненными предложениями в папку\n",
        "pair2Align.save_table(proj.aligned_df, output_dir, out_filename=project_name)"
      ],
      "metadata": {
        "id": "fNINOD61zopV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# если хотим посмотреть на выровненную книжку, сохраняем ее в папку books\n",
        "# ячейка закоменчена чтобы случайно не запустилась\n",
        "# proj.save_book(output_filename=project_name, output_dir='books')"
      ],
      "metadata": {
        "id": "V7CXcMzJtasZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## После того, как мы закончили обрабатывать файлы, можно сохранить папку results в архив и скачать"
      ],
      "metadata": {
        "id": "0tI6-C9a2ZCy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ячейка закоменчена чтобы случайно не запустилась"
      ],
      "metadata": {
        "id": "Qpw-O0BWShuM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# zip_filename = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "# shutil.make_archive(zip_filename, 'zip', output_dir)\n",
        "\n",
        "# from google.colab import files\n",
        "\n",
        "# files.download(zip_filename+'.zip')"
      ],
      "metadata": {
        "id": "6XjWLqMQv8sl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "2ccf9f15-8af8-448e-d39e-3fbf6084ded7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_74c4754a-d143-4c71-be78-f26350a7f3ca\", \"20250531_124116.zip\", 126590)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}